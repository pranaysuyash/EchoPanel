# AUD-002 Microphone Audio Capture (AVAudioEngine)

## Summary

- Origin: Mixed
- Status: Implemented
- Captures microphone audio using AVAudioEngine, converts to 16kHz mono PCM16, applies volume limiting, and emits 20ms chunks for ASR processing.
- Boundaries crossed: OS (AVAudioEngine) / Process (audio conversion)
- Primary components: MicrophoneCaptureManager, AVAudioEngine, AVAudioConverter

## Triggers and Preconditions

- Triggers: Session start when audioSource includes .microphone
- Preconditions: Microphone permission granted, audio capture not already running

## Sequence (Happy Path)

1. Permission status check via AVCaptureDevice.authorizationStatus(for: .audio)
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: func checkPermission() -> Bool { AVCaptureDevice.authorizationStatus(for: .audio) == .authorized }
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Permission check (MicrophoneCaptureManager.swift:37-39)

2. Get input node and native format from AVAudioEngine
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: let inputNode = audioEngine.inputNode; let inputFormat = inputNode.outputFormat(forBus: 0)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Audio engine setup (MicrophoneCaptureManager.swift:41-65)

3. Create target format (16kHz mono Float32) and AVAudioConverter
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: let targetFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: 16000, channels: 1, interleaved: false)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Converter creation (MicrophoneCaptureManager.swift:52-55)

4. Install tap on input node with buffer processing callback
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, \_ in self?.processAudioBuffer(...) }
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Tap installation (MicrophoneCaptureManager.swift:57-59)

5. Prepare and start audio engine
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: audioEngine.prepare(); try audioEngine.start()
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Engine start (MicrophoneCaptureManager.swift:61-64)

6. Process incoming AVAudioPCMBuffer in callback
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: private func processAudioBuffer(buffer: AVAudioPCMBuffer, ...)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Buffer processing loop (MicrophoneCaptureManager.swift:76-109)

7. Convert audio to 16kHz mono using AVAudioConverter
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: converter.convert(to: outputBuffer)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Buffer processing loop

8. Apply volume limiter to prevent clipping
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: limitedSamples = applyLimiter(samples: samples, count: frameCount)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Volume limiting (MicrophoneCaptureManager.swift:102)

9. Update audio level EMA for monitoring
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: levelEMA = levelEMA _ 0.9 + rms _ 0.1
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Audio level update (MicrophoneCaptureManager.swift:105)

10. Convert Float32 to Int16 PCM16 and chunk into 20ms frames
    - Evidence:
      - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: let pcm16 = samples.map { Int16(max(-32768, min(32767, $0 \* 32767))) }
      - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Chunk emission (MicrophoneCaptureManager.swift:108, 157-185)

11. Emit PCM frame with "mic" source tag
    - Evidence:
      - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: onPCMFrame?(data, "mic")
      - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Chunk emission

## Inputs and Outputs

- Inputs: Native microphone audio (typically 48kHz, variable format) from AVAudioPCMBuffer
- Outputs: 16kHz mono PCM16 Int16 chunks (320 bytes = 20ms)
- Side effects: AVAudioEngine active, audio level monitoring updates

## Failure Modes

- Microphone permission denied:
  - Where detected: AVCaptureDevice.authorizationStatus returns not .authorized
  - Current handling: Throws MicCaptureError (implied)
  - User-visible outcome: Session fails with permission error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: func checkPermission() -> Bool

- Audio engine start failure:
  - Where detected: audioEngine.start() throws
  - Current handling: Exception propagates as generic error
  - User-visible outcome: Session fails with audio engine error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: try audioEngine.start()

- Converter creation failure:
  - Where detected: AVAudioConverter(from:to:) returns nil
  - Current handling: Throws MicCaptureError.converterCreationFailed
  - User-visible outcome: Session fails with converter error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: guard let converter = AVAudioConverter(from: inputFormat, to: targetFormat) else { throw MicCaptureError.converterCreationFailed }

- Target format creation failure:
  - Where detected: AVAudioFormat init returns nil
  - Current handling: Throws MicCaptureError.formatCreationFailed
  - User-visible outcome: Session fails with format error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: guard let targetFormat = AVAudioFormat(...) else { throw MicCaptureError.formatCreationFailed }

- Tap installation failure:
  - Where detected: inputNode.installTap throws
  - Current handling: Exception propagates
  - User-visible outcome: Session fails with tap installation error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: inputNode.installTap(...)

- Buffer allocation failure:
  - Where detected: AVAudioPCMBuffer init returns nil
  - Current handling: ✅ Logs error, increments framesDropped counter, returns early
  - User-visible outcome: Brief audio gap, logged for debugging
  - Evidence: Code: `MicrophoneCaptureManager.swift:104-109`

- Conversion failure:
  - Where detected: converter.convert returns error status
  - Current handling: ✅ Logs error with details, increments framesDropped counter
  - User-visible outcome: Brief audio gap, logged for debugging  
  - Evidence: Code: `MicrophoneCaptureManager.swift:119-127`

- Device disconnected:
  - Where detected: No more buffers received
  - Current handling: No explicit handling (macOS limitation - AVAudioSession is iOS-only)
  - User-visible outcome: Audio capture stops
  - Evidence: Noted in code comments

- Permission revoked during capture:
  - Where detected: `checkPermissionStatus()` called every ~2 seconds
  - Current handling: ✅ Logs error, stops capture, reports error via onError callback
  - User-visible outcome: Session ends with permission error
  - Evidence: Code: `MicrophoneCaptureManager.swift:144-157`

## Data and Storage

- No persistent storage
- Temporary buffers for audio conversion
- PCM remainder state for chunking across frames
- Level EMA state for monitoring

## Observability

- ✅ Debug logging on start/stop (NSLog + StructuredLogger)
- ✅ Audio level updates via callback (thread-safe with NSLock)
- ✅ Structured logging for lifecycle events (via Task { @MainActor })
- ✅ Metrics: framesProcessed, framesDropped, bufferUnderruns
- ✅ Error logging with context (format details, frame counts)
- ✅ Slow processing detection (>10ms threshold)
- ✅ Periodic permission status checks

## Improvements Made (2026-02-12)

### ✅ Thread safety of level EMA updates
- Added `levelLock` NSLock for thread-safe level EMA updates
- Evidence: `MicrophoneCaptureManager.swift:16` - `private let levelLock = NSLock()`

### ✅ Permission revocation detection
- Added `checkPermissionStatus()` method
- Called periodically every ~2 seconds (every 100 buffers)
- Stops capture and reports error if permission revoked
- Evidence: `MicrophoneCaptureManager.swift:144-157`

### ✅ Buffer allocation/conversion error handling
- Buffer allocation failures now logged and counted as dropped frames
- Conversion failures now logged with error details
- Evidence: `MicrophoneCaptureManager.swift:104-109` (buffer), `MicrophoneCaptureManager.swift:119-127` (conversion)

### ✅ Metrics tracking
- Added `framesProcessed`, `framesDropped`, `bufferUnderruns` counters
- Thread-safe access via `metricsLock`
- Public `getMetrics()` method for monitoring
- Evidence: `MicrophoneCaptureManager.swift:33-36`, `MicrophoneCaptureManager.swift:285-301`

### ✅ Structured logging
- Lifecycle events logged via StructuredLogger
- Real-time errors logged via NSLog (background thread safe)
- Error context includes format details, frame counts
- Evidence: Throughout `MicrophoneCaptureManager.swift`

### ⚠️ Device change monitoring (macOS limitation)
- AVAudioSession is iOS-only, not available on macOS
- macOS would require AudioObjectPropertyListener implementation
- Not implemented - documented as known limitation

## Open Questions and Follow-up Tasks

### Implementation Items (Complete)
- ~~Thread safety of level EMA updates~~ ✅ FIXED
- ~~Permission revocation detection~~ ✅ FIXED
- ~~Buffer allocation/conversion error handling~~ ✅ FIXED
- ~~Metrics tracking~~ ✅ FIXED
- ~~Structured logging~~ ✅ FIXED

### Assessment: Device Change Monitoring
**Current State:** AUD-008 (DeviceHotSwapManager) already handles microphone device disconnect/connect via `AVCaptureDeviceWasConnected/Disconnected` notifications. This covers the primary hot-swap use case.

**What was referenced as missing:**
- Real-time default device change detection (when user switches input in System Settings without disconnect)
- Would require `AudioObjectPropertyListener` with `kAudioHardwarePropertyDefaultInputDevice`

**Decision: DEFER** ❌
- **Implementation:** Would require Core Audio `AudioObjectPropertyListener` framework
- **Complexity:** High (Core Audio callbacks, audio object lifecycle management)
- **User Impact:** Low - AUD-008's 2s periodic verification catches most changes; user switching default mic mid-capture is rare
- **Workaround:** Existing 2s periodic check in AUD-008 provides acceptable coverage
- **Risk:** Core Audio callbacks can introduce instability if not handled carefully
- **Priority:** P2 - Enhancement, not launch-critical

### Known Limitations
- Real-time default device property monitoring deferred (requires Core Audio `AudioObjectPropertyListener`)
- Periodic verification (2s) in AUD-008 provides acceptable coverage for most use cases

### Test Gaps (Future)
- [ ] Add unit tests for metrics tracking (getMetrics(), framesDropped, etc.)
- [ ] Add unit tests for permission revocation handling (MicrophoneCaptureManager)
- [ ] Test buffer overflow scenarios under heavy load
- [ ] End-to-end device change during active session (integration with AUD-008)


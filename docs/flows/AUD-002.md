# AUD-002 Microphone Audio Capture (AVAudioEngine)

## Summary

- Origin: Mixed
- Status: Implemented
- Captures microphone audio using AVAudioEngine, converts to 16kHz mono PCM16, applies volume limiting, and emits 20ms chunks for ASR processing.
- Boundaries crossed: OS (AVAudioEngine) / Process (audio conversion)
- Primary components: MicrophoneCaptureManager, AVAudioEngine, AVAudioConverter

## Triggers and Preconditions

- Triggers: Session start when audioSource includes .microphone
- Preconditions: Microphone permission granted, audio capture not already running

## Sequence (Happy Path)

1. Permission status check via AVCaptureDevice.authorizationStatus(for: .audio)
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: func checkPermission() -> Bool { AVCaptureDevice.authorizationStatus(for: .audio) == .authorized }
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Permission check (MicrophoneCaptureManager.swift:37-39)

2. Get input node and native format from AVAudioEngine
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: let inputNode = audioEngine.inputNode; let inputFormat = inputNode.outputFormat(forBus: 0)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Audio engine setup (MicrophoneCaptureManager.swift:41-65)

3. Create target format (16kHz mono Float32) and AVAudioConverter
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: let targetFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: 16000, channels: 1, interleaved: false)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Converter creation (MicrophoneCaptureManager.swift:52-55)

4. Install tap on input node with buffer processing callback
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] buffer, \_ in self?.processAudioBuffer(...) }
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Tap installation (MicrophoneCaptureManager.swift:57-59)

5. Prepare and start audio engine
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: audioEngine.prepare(); try audioEngine.start()
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Engine start (MicrophoneCaptureManager.swift:61-64)

6. Process incoming AVAudioPCMBuffer in callback
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: private func processAudioBuffer(buffer: AVAudioPCMBuffer, ...)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Buffer processing loop (MicrophoneCaptureManager.swift:76-109)

7. Convert audio to 16kHz mono using AVAudioConverter
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: converter.convert(to: outputBuffer)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Buffer processing loop

8. Apply volume limiter to prevent clipping
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: limitedSamples = applyLimiter(samples: samples, count: frameCount)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Volume limiting (MicrophoneCaptureManager.swift:102)

9. Update audio level EMA for monitoring
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: levelEMA = levelEMA _ 0.9 + rms _ 0.1
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Audio level update (MicrophoneCaptureManager.swift:105)

10. Convert Float32 to Int16 PCM16 and chunk into 20ms frames
    - Evidence:
      - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: let pcm16 = samples.map { Int16(max(-32768, min(32767, $0 \* 32767))) }
      - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Chunk emission (MicrophoneCaptureManager.swift:108, 157-185)

11. Emit PCM frame with "mic" source tag
    - Evidence:
      - Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: onPCMFrame?(data, "mic")
      - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Chunk emission

## Inputs and Outputs

- Inputs: Native microphone audio (typically 48kHz, variable format) from AVAudioPCMBuffer
- Outputs: 16kHz mono PCM16 Int16 chunks (320 bytes = 20ms)
- Side effects: AVAudioEngine active, audio level monitoring updates

## Failure Modes

- Microphone permission denied:
  - Where detected: AVCaptureDevice.authorizationStatus returns not .authorized
  - Current handling: Throws MicCaptureError (implied)
  - User-visible outcome: Session fails with permission error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: func checkPermission() -> Bool

- Audio engine start failure:
  - Where detected: audioEngine.start() throws
  - Current handling: Exception propagates as generic error
  - User-visible outcome: Session fails with audio engine error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: try audioEngine.start()

- Converter creation failure:
  - Where detected: AVAudioConverter(from:to:) returns nil
  - Current handling: Throws MicCaptureError.converterCreationFailed
  - User-visible outcome: Session fails with converter error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: guard let converter = AVAudioConverter(from: inputFormat, to: targetFormat) else { throw MicCaptureError.converterCreationFailed }

- Target format creation failure:
  - Where detected: AVAudioFormat init returns nil
  - Current handling: Throws MicCaptureError.formatCreationFailed
  - User-visible outcome: Session fails with format error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: guard let targetFormat = AVAudioFormat(...) else { throw MicCaptureError.formatCreationFailed }

- Tap installation failure:
  - Where detected: inputNode.installTap throws
  - Current handling: Exception propagates
  - User-visible outcome: Session fails with tap installation error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: inputNode.installTap(...)

- Buffer allocation failure:
  - Where detected: AVAudioPCMBuffer init returns nil
  - Current handling: Frame dropped silently
  - User-visible outcome: Brief audio gap
  - Evidence: Code: macapp/MeetingListenerApp/Sources/MicrophoneCaptureManager.swift :: guard let outputBuffer = AVAudioPCMBuffer(...)

- Conversion failure:
  - Where detected: converter.convert returns false
  - Current handling: Frame dropped silently
  - User-visible outcome: Brief audio gap
  - Evidence: Assumed - code doesn't check convert result

- Device disconnected:
  - Where detected: No more buffers received
  - Current handling: No explicit handling
  - User-visible outcome: Audio capture stops
  - Evidence: Assumed - no explicit device monitoring

## Data and Storage

- No persistent storage
- Temporary buffers for audio conversion
- PCM remainder state for chunking across frames
- Level EMA state for monitoring

## Observability

- Debug logging on start/stop
- Audio level updates via callback
- No structured logging or metrics

## Open Questions and Follow-up Tasks

- Thread safety of level EMA updates
- No handling for device changes during capture
- Potential buffer overflow if processing slower than input
- Test gaps: Device hot-swap, permission revocation during capture</content>
  <parameter name="filePath">/Users/pranay/Projects/EchoPanel/docs/flows/AUD-002.md

# AUD-001 System Audio Capture (ScreenCaptureKit)

## Summary

- Origin: Mixed
- Status: Implemented
- Captures system audio output using macOS ScreenCaptureKit, converts to 16kHz mono PCM16, applies volume limiting, and emits 20ms chunks for ASR processing.
- Boundaries crossed: OS (ScreenCaptureKit) / Process (audio conversion)
- Primary components: AudioCaptureManager, SCStream, AVAudioConverter

## Triggers and Preconditions

- Triggers: Session start when audioSource includes .system
- Preconditions: macOS 13+, screen recording permission granted, system audio not already captured

## Sequence (Happy Path)

1. Permission preflight check via CGPreflightScreenCaptureAccess()
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: func requestPermission() async -> Bool { if CGPreflightScreenCaptureAccess() }
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Permission check (AudioCaptureManager.swift:61-66)

2. Discover shareable content and select main display
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: true)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: ScreenCaptureKit content discovery (AudioCaptureManager.swift:73-78)

3. Configure SCStream with audio capture enabled and current process audio excluded
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: configuration.capturesAudio = true; configuration.excludesCurrentProcessAudio = true
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Stream configuration (AudioCaptureManager.swift:80-86)

4. Register sample handler for screen and audio output types
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: stream.addStreamOutput(sampleHandler, type: .screen, ...); stream.addStreamOutput(sampleHandler, type: .audio, ...)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Stream output registration (AudioCaptureManager.swift:88-90)

5. Start capture stream
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: try await stream.startCapture()
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Stream start (AudioCaptureManager.swift:90)

6. Receive CMSampleBuffer in sample handler callback
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: func stream(\_:didOutputSampleBuffer:of:)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Sample buffer callback (AudioCaptureManager.swift:343-374, AudioSampleHandler)

7. Extract audio format and create AVAudioPCMBuffer from CMSampleBuffer
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: let inputBuffer = AVAudioPCMBuffer(pcmFormat: inputFormat, frameCapacity: inputFrameCount)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Audio processing (AudioCaptureManager.swift:106-214, processAudio)

8. Convert audio to 16kHz mono Float32 using AVAudioConverter
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: let converter = AVAudioConverter(from: inputFormat, to: targetFormat)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Converter setup (AudioCaptureManager.swift:147-160)

9. Apply volume limiter to prevent clipping
   - Evidence:
     - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: limitedSamples = applyLimiter(samples: samples, count: frameCount)
     - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Volume limiting (AudioCaptureManager.swift:210)

10. Convert Float32 to Int16 PCM16 and chunk into 20ms frames (320 bytes)
    - Evidence:
      - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: let pcm16 = samples.map { Int16(max(-32768, min(32767, $0 \* 32767))) }
      - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Chunk emission (AudioCaptureManager.swift:213, 255-284)

11. Emit PCM frame with "system" source tag
    - Evidence:
      - Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: onPCMFrame?(data, "system")
      - Docs: docs/audit/audio-pipeline-deep-dive-20260211.md :: Chunk emission

## Inputs and Outputs

- Inputs: Native system audio (typically 48kHz, variable format) from CMSampleBuffer
- Outputs: 16kHz mono PCM16 Int16 chunks (320 bytes = 20ms)
- Side effects: SCStream active, audio quality monitoring updates, screen frame counting

## Failure Modes

- Screen recording permission denied:
  - Where detected: CGPreflightScreenCaptureAccess() returns false
  - Current handling: Throws CaptureError.permissionDenied
  - User-visible outcome: Session fails with permission error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: guard CGPreflightScreenCaptureAccess() else { throw CaptureError.permissionDenied }

- Unsupported OS version:
  - Where detected: #available(macOS 13, \*) check
  - Current handling: Throws CaptureError.unsupportedOS
  - User-visible outcome: Session fails with OS compatibility error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: guard #available(macOS 13, \*) else { throw CaptureError.unsupportedOS }

- No display available:
  - Where detected: content.displays empty
  - Current handling: Throws CaptureError.noDisplay
  - User-visible outcome: Session fails with display error
  - Evidence: Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: guard let display else { throw CaptureError.noDisplay }

- Stream start failure:
  - Where detected: stream.startCapture() throws
  - Current handling: Exception logged, not rethrown
  - User-visible outcome: Capture appears to start but no audio flows
  - Evidence: Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: try await stream.startCapture() (wrapped in do-catch)

- Audio format extraction failure:
  - Where detected: CMSampleBufferGetFormatDescription returns null
  - Current handling: Frame dropped, logged
  - User-visible outcome: Brief audio gap
  - Evidence: Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer)

- Audio conversion failure:
  - Where detected: converter.convert returns error
  - Current handling: Frame dropped, logged
  - User-visible outcome: Brief audio gap
  - Evidence: Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: guard converter.convert(...) else { log error }

- Memory allocation failure for buffers:
  - Where detected: AVAudioPCMBuffer init fails
  - Current handling: Frame dropped, logged
  - User-visible outcome: Brief audio gap
  - Evidence: Code: macapp/MeetingListenerApp/Sources/AudioCaptureManager.swift :: guard let inputBuffer = AVAudioPCMBuffer(...)

- Stream stops unexpectedly:
  - Where detected: No more sample buffers received
  - Current handling: No explicit handling, capture appears stopped
  - User-visible outcome: Audio capture ends
  - Evidence: Assumed - no explicit stop detection

## Data and Storage

- No persistent storage
- Temporary buffers for audio conversion
- PCM remainder state for chunking across frames

## Observability

- Debug logging on stream start/stop
- Audio quality metrics (RMS, clipping, silence ratios)
- Sample count and screen frame count updates
- No structured logging or metrics emission

## Open Questions and Follow-up Tasks

- Thread safety of quality EMA updates (updated from capture thread without sync)
- Memory leak potential if stream not properly stopped
- No handling for display disconnection during capture
- Test gaps: Permission revocation during active capture, display changes</content>
  <parameter name="filePath">/Users/pranay/Projects/EchoPanel/docs/flows/AUD-001.md

# AUD-007 Session-End Diarization (pyannote)

## Summary

- Origin: Mixed
- Status: Implemented
- At session end, concatenates PCM buffers from all sources, runs pyannote.audio speaker diarization pipeline, merges adjacent segments by speaker, assigns friendly names, and merges speaker labels into transcript segments.
- Boundaries crossed: Process (batch inference) / Model (pyannote) / Network (HuggingFace download)
- Primary components: diarize_pcm, pyannote.audio Pipeline, merge_transcript_with_speakers

## Triggers and Preconditions

- Triggers: Session finalization, after ASR completes
- Preconditions: Diarization enabled, HF token set, pyannote available, PCM buffers collected

## Sequence (Happy Path)

1. Check diarization availability and token
   - Evidence:
     - Code: server/services/diarization.py :: def is_diarization_available() -> bool
     - Code: server/services/diarization.py :: token = os.getenv("ECHOPANEL_HF_TOKEN")

2. Load pyannote pipeline if not cached
   - Evidence:
     - Code: server/services/diarization.py :: \_PIPELINE = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1", use_auth_token=token)
     - Code: server/services/diarization.py :: def \_get_pipeline() -> Optional["Pipeline"]

3. Concatenate PCM buffers from all sources
   - Evidence:
     - Code: server/api/ws_live_listener.py :: pcm_buffers_by_source[source_key] = bytearray()
     - Code: server/api/ws_live_listener.py :: pcm_buffer.extend(chunk)

4. Convert PCM16 to float32 waveform tensor
   - Evidence:
     - Code: server/services/diarization.py :: audio = np.frombuffer(pcm_bytes, dtype=np.int16).astype(np.float32) / 32768.0
     - Code: server/services/diarization.py :: waveform = torch.from_numpy(audio).unsqueeze(0)

5. Run diarization pipeline inference
   - Evidence:
     - Code: server/services/diarization.py :: diarization = pipeline({"waveform": waveform, "sample_rate": sample_rate})

6. Extract speaker segments from diarization results
   - Evidence:
     - Code: server/services/diarization.py :: for turn, \_, speaker in diarization.itertracks(yield_label=True)

7. Merge adjacent segments from same speaker
   - Evidence:
     - Code: server/services/diarization.py :: def \_merge_adjacent_segments(segments: List[SpeakerSegment], gap_threshold: float = 0.5)

8. Assign friendly speaker names (Speaker 1, Speaker 2, etc.)
   - Evidence:
     - Code: server/services/diarization.py :: def \_assign_speaker_names(segments: List[SpeakerSegment])

9. Merge speaker labels into transcript by time overlap
   - Evidence:
     - Code: server/services/diarization.py :: def merge_transcript_with_speakers(transcript: List[dict], speaker_segments: List[dict])
     - Code: server/services/diarization.py :: mid = (t0 + t1) / 2.0

10. Include diarization results in final summary
    - Evidence:
      - Code: server/api/ws_live_listener.py :: final_summary_json["diarization"] = diarization_result

## Inputs and Outputs

- Inputs: PCM16 bytes from session buffers, transcript segments
- Outputs: List of speaker segments with timestamps, updated transcript with speaker fields
- Side effects: Pipeline cached globally, HF token used for auth

## Failure Modes

- Dependencies unavailable:
  - Where detected: np is None or torch is None or Pipeline is None
  - Current handling: Return empty list
  - User-visible outcome: No speaker labels in output
  - Evidence: Code: server/services/diarization.py :: if np is None or torch is None: return []

- HF token missing:
  - Where detected: os.getenv("ECHOPANEL_HF_TOKEN") is None
  - Current handling: Return empty list
  - User-visible outcome: No speaker labels
  - Evidence: Code: server/services/diarization.py :: if not token: return None

- Pipeline loading failure:
  - Where detected: Pipeline.from_pretrained() throws
  - Current handling: Log error, return None
  - User-visible outcome: No speaker labels
  - Evidence: Code: server/services/diarization.py :: except Exception as e: logger.error(f"Failed to load diarization pipeline: {e}")

- Inference failure:
  - Where detected: pipeline() call throws
  - Current handling: Log error, return empty list
  - User-visible outcome: No speaker labels
  - Evidence: Code: server/services/diarization.py :: except Exception as e: logger.error(f"Error during diarization processing: {e}")

- Empty or invalid PCM:
  - Where detected: pcm_bytes empty or invalid
  - Current handling: Process succeeds but returns empty segments
  - User-visible outcome: No speaker labels
  - Evidence: Assumed - no explicit validation

- Memory issues:
  - Where detected: Large PCM buffers cause OOM
  - Current handling: Exception propagates
  - User-visible outcome: Session fails
  - Evidence: Assumed - no explicit memory checks

## Data and Storage

- Global pipeline cache (\_PIPELINE)
- PCM buffers per source in SessionState
- No persistent storage

## Observability

- Debug logging: Pipeline loading, segment counts, errors
- No metrics or structured logging
- Results included in final JSON summary

## Open Questions and Follow-up Tasks

- Per-source diarization: Currently concatenates all sources, may not work well for mixed audio
- Speaker naming: Simple sequential assignment, no persistence across sessions
- Performance: Batch processing at end, may be slow for long sessions
- Test gaps: HF token validation, pipeline loading failures, memory limits


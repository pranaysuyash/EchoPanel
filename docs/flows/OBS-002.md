# OBS-002 Metrics Collection Flow (Python Server)

## Summary

- Origin: Code-only
- Status: Implemented
- Server collects in-memory metrics (counters, gauges, histograms) and emits them to client every 1Hz for real-time observability.
- Boundaries crossed: Network (WebSocket emission)
- Primary components (coarse list): MetricsRegistry, ws_live_listener.py

## Triggers and Preconditions

- Triggers (user action, event, schedule, startup, etc.): WebSocket session established, metrics loop starts
- Preconditions (permissions, settings flags, availability, model cached, etc.): Session state initialized

## Sequence (Happy Path)

Use numbered sequence. Each step must include evidence.
For each step:

1. <what happens>
   - Evidence:
     - Code: path :: symbol/event/string
     - Docs: path :: heading/snippet
   - Notes: (only if needed)

1. Metrics registry initialized with default metrics
   - Evidence:
     - Code: server/services/metrics_registry.py :: \_init_default_metrics() creates counters, gauges, histograms
     - Docs: docs/OBSERVABILITY_IMPLEMENTATION.md :: Lightweight in-memory metrics collection
   - Notes: Thread-safe singleton registry

1. Metrics loop starts in WebSocket handler
   - Evidence:
     - Code: server/api/ws_live_listener.py :: asyncio.create_task(metrics_loop())
     - Docs: docs/IMPLEMENTATION_SUMMARY_OBSERVABILITY.md :: Server Metrics Registry
   - Notes: Runs every 1 second per session

1. Queue metrics calculated for each source
   - Evidence:
     - Code: server/api/ws_live_listener.py :: queue_depth = q.qsize(), fill_ratio calculation
   - Notes: Per-source queue monitoring

1. Processing metrics computed from recent history
   - Evidence:
     - Code: server/api/ws_live_listener.py :: avg_infer_time from state.asr_processing_times[-10:]
   - Notes: Rolling average over last 10 chunks

1. Metrics payload assembled with correlation IDs
   - Evidence:
     - Code: server/api/ws_live_listener.py :: metrics_payload dict with session_id, attempt_id, connection_id
     - Docs: docs/WS_CONTRACT.md :: metrics message type
   - Notes: Includes provider, model, VAD status

1. Payload sent to client via WebSocket
   - Evidence:
     - Code: server/api/ws_live_listener.py :: await ws_send(state, websocket, metrics_payload)
   - Notes: Real-time metrics emission

1. Registry updated with current values
   - Evidence:
     - Code: server/api/ws_live_listener.py :: registry.set_gauge("queue_depth", ...), registry.observe_histogram(...)
   - Notes: Persistent metrics for aggregation

## Inputs and Outputs

- Inputs:
  - Queue states, processing times, dropped frame counts
  - Session correlation IDs
- Outputs:
  - WebSocket metrics messages to client
  - Updated registry values
- Side effects (writes, network calls, model loads, UI state changes): WebSocket message emission, registry state updates

## Failure Modes

List 5â€“10 realistic failures:

- Failure: Metrics loop crashes
  - Where detected: Exception in metrics_loop
  - Current handling (as evidenced): Logged error, loop terminates
  - User-visible outcome (if any): No more metrics emission for session
  - Evidence: Code: server/api/ws_live_listener.py :: except Exception as e: logger.error

- Failure: WebSocket send fails during metrics emission
  - Where detected: ws_send raises exception
  - Current handling (as evidenced): Exception propagates, may crash metrics loop
  - User-visible outcome (if any): Metrics loop stops
  - Evidence: Code: server/api/ws_live_listener.py :: await ws_send() without try/catch

- Failure: Registry operations fail
  - Where detected: Thread lock contention or memory issues
  - Current handling (as evidenced): Thread-safe with locks
  - User-visible outcome (if any): Metrics updates may block
  - Evidence: Code: server/services/metrics_registry.py :: with self.\_lock

- Failure: Session ends before metrics loop starts
  - Where detected: state.closed check
  - Current handling (as evidenced): Loop exits early
  - User-visible outcome (if any): No metrics emitted
  - Evidence: Code: server/api/ws_live_listener.py :: if state.closed: return

- Failure: Degrade ladder status retrieval fails
  - Where detected: state.degrade_ladder.get_status() exception
  - Current handling (as evidenced): try/except, logged as debug
  - User-visible outcome (if any): Degrade status omitted from metrics
  - Evidence: Code: server/api/ws_live_listener.py :: except Exception as e: logger.debug

## Data and Storage

- What data is produced/consumed: Queue depths, processing times, dropped frames, correlation IDs
- Where it is stored (DB/files/userData/etc.): In-memory MetricsRegistry singleton
- Retention / deletion controls (if documented): Metrics persist until server restart

## Observability

- Logs/events emitted: Error logging if metrics loop fails
- Correlation IDs / session IDs (if any): Included in every metrics payload
- Metrics/traces (if any): Self-metrics (registry tracks its own operations)
  Evidence: Code: server/api/ws_live_listener.py :: registry.set_gauge, registry.observe_histogram

## Open Questions and Follow-up Tasks

- Questions that cannot be answered from current evidence: How are metrics aggregated across sessions?
- Documentation gaps to fill: Metrics export to external monitoring systems
- Test gaps to add (note only, no implementation): Test metrics accuracy under load


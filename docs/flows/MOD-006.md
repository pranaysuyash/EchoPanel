# MOD-006 Auto Device Selection (Metal/CUDA/CPU)

## Summary

- Origin: Mixed
- Status: Implemented
- Automatic device selection for ASR models based on platform capabilities and configuration, prioritizing GPU acceleration (Metal on macOS, CUDA on Linux/Windows) with CPU fallback.
- Boundaries crossed: Model / OS
- Primary components (coarse list): ASR providers (faster-whisper, whisper.cpp), capability detector, configuration

## Triggers and Preconditions

- Triggers (user action, event, schedule, startup, etc.): Model load (lazy or eager), provider initialization
- Preconditions (permissions, settings flags, availability, model cached, etc.): Model not yet loaded, device configuration set (or defaults apply)

## Sequence (Happy Path)

1. Get device from config
   - Evidence:
     - Code: server/services/provider_faster_whisper.py:81-82
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:987-989
2. Auto-detect on macOS (fallback to CPU since CTranslate2 doesn't support MPS/Metal)
   - Evidence:
     - Code: server/services/provider_faster_whisper.py:85-88
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:991-995
3. Get compute type from config
   - Evidence:
     - Code: server/services/provider_faster_whisper.py:90
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:997-998
4. Force int8 on CPU if float16 specified
   - Evidence:
     - Code: server/services/provider_faster_whisper.py:92-95
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1000-1004
5. Load model with selected device and compute type
   - Evidence:
     - Code: server/services/provider_faster_whisper.py:97-100
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1006-1011
6. For whisper.cpp: Get default config preferring Metal on macOS
   - Evidence:
     - Code: server/services/provider_whisper_cpp.py:88-96
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1016-1024
7. Determine Metal usage based on config and Apple Silicon detection
   - Evidence:
     - Code: server/services/provider_whisper_cpp.py:145-147
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1026-1028
8. Detect Apple Silicon
   - Evidence:
     - Code: server/services/provider_whisper_cpp.py:175-181
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1030-1036
9. Set Metal parameters and calculate optimal threads
   - Evidence:
     - Code: server/services/provider_whisper_cpp.py:149-159, 183-193
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1038-1054
10. Load whisper.cpp model with parameters
    - Evidence:
      - Code: server/services/provider_whisper_cpp.py:161-169
      - Docs: docs/audit/asr-model-lifecycle-20260211.md:1056-1064

## Inputs and Outputs

- Inputs: Device config (auto/metal/cuda/cpu), compute type config, platform detection
- Outputs: Selected device (cpu/metal/cuda), adjusted compute type, loaded model instance
- Side effects (writes, network calls, model loads, UI state changes): Model loading, logging device selection

## Failure Modes

- Failure: Device config invalid
  - Where detected: Config parsing
  - Current handling (as evidenced): Fallback to defaults
  - User-visible outcome (if any): Logs warning, uses CPU
  - Evidence: Assumed from config handling
- Failure: Metal requested but not Apple Silicon
  - Where detected: \_is_apple_silicon check
  - Current handling (as evidenced): Fallback to CPU
  - User-visible outcome (if any): Log "Using CPU inference"
  - Evidence: provider_whisper_cpp.py:149-159
- Failure: float16 on CPU
  - Where detected: Compute type check
  - Current handling (as evidenced): Force to int8
  - User-visible outcome (if any): Log "Forced compute_type='int8'"
  - Evidence: provider_faster_whisper.py:92-95
- Failure: Model load fails on selected device
  - Where detected: Try-catch in load
  - Current handling (as evidenced): Exception raised, handled by caller
  - User-visible outcome (if any): Error in logs, potential degrade ladder activation
  - Evidence: Assumed from error handling patterns
- Failure: Platform detection fails
  - Where detected: platform.system() or machine()
  - Current handling (as evidenced): Defaults to CPU
  - User-visible outcome (if any): CPU usage
  - Evidence: provider_whisper_cpp.py:175-181

## Data and Storage

- What data is produced/consumed: Device preference, compute type, platform info
- Where it is stored (DB/files/userData/etc.): In-memory config, environment variables
- Retention / deletion controls (if documented): Session lifetime

## Observability

- Logs/events emitted: Device selection logs ("Using Metal GPU acceleration", "Using CPU inference", "Forced compute_type='int8'")
- Correlation IDs / session IDs (if any): None specific
- Metrics/traces (if any): Load time metrics
- Evidence: provider_faster_whisper.py:95, provider_whisper_cpp.py:152-155, docs/audit/asr-model-lifecycle-20260211.md

## Open Questions and Follow-up Tasks

- Questions that cannot be answered from current evidence: Priority order for CUDA vs other GPUs
- Documentation gaps: Device selection priority order, compute type compatibility matrix
- Test gaps to add (note only, no implementation): Test device fallback on different platforms</content>
  <parameter name="filePath">/Users/pranay/Projects/EchoPanel/docs/flows/MOD-006.md

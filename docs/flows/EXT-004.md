# EXT-004 Session Start

## Summary

- Origin: Code-only
- Status: Implemented
- Initiates a new recording session by checking permissions, starting audio capture, establishing WebSocket connection to backend, and waiting for streaming acknowledgment. Transitions app state from idle to listening.
- Boundaries crossed: UI / OS (permissions) / Process (audio capture) / Network (WebSocket)
- Primary components (coarse list): AppState, AudioCaptureManager, MicrophoneCaptureManager, WebSocketStreamer, ws_live_listener

## Triggers and Preconditions

- Triggers: User clicks start button or invokes start action
- Preconditions: Backend server running and healthy, audio source selected, no active session

## Sequence (Happy Path)

Use numbered sequence. Each step must include evidence.
For each step:

1. <what happens>
   - Evidence:
     - Code: path :: symbol/event/string
     - Docs: path :: heading/snippet
   - Notes: (only if needed)

1. User initiates session start, app sets sessionState to .starting
   - Evidence:
     - Code: AppState.swift :: startSession() :: sessionState = .starting
     - Docs: flow-atlas-20260211.md :: EXT-004 Session Start

1. Generate session ID and attempt ID, create session bundle for observability
   - Evidence:
     - Code: AppState.swift :: startSession() :: let id = UUID().uuidString; sessionID = id
     - Code: AppState.swift :: startSession() :: let bundle = SessionBundleManager.shared.createBundle

1. Check and request screen recording permission if system audio needed
   - Evidence:
     - Code: AppState.swift :: startSession() :: if audioSource == .system || audioSource == .both
     - Code: AppState.swift :: startSession() :: granted = await audioCapture.requestPermission()

1. Check and request microphone permission if mic audio needed
   - Evidence:
     - Code: AppState.swift :: startSession() :: if audioSource == .microphone || audioSource == .both
     - Code: AppState.swift :: startSession() :: let micGranted = await micCapture.requestPermission()

1. Start audio capture (system and/or microphone)
   - Evidence:
     - Code: AppState.swift :: startSession() :: try await audioCapture.startCapture()
     - Code: AppState.swift :: startSession() :: try micCapture.startCapture()

1. Establish WebSocket connection with auth headers and send start message with session metadata
   - Evidence:
     - Code: WebSocketStreamer.swift :: connect() :: session.webSocketTask(with: BackendConfig.webSocketRequest)
     - Code: BackendConfig.swift :: webSocketRequest :: sets Authorization + x-echopanel-token headers when token exists
     - Code: WebSocketStreamer.swift :: sendStart() :: sendJSON(["type": "start", "session_id": sessionID, ...])

1. Backend receives start message, validates format, acquires session slot
   - Evidence:
     - Code: ws_live_listener.py :: if msg_type == "start"
     - Code: ws_live_listener.py :: session_acquired = await controller.acquire_session(timeout=5.0)

1. Backend initializes ASR provider, degrade ladder, sends streaming acknowledgment
   - Evidence:
     - Code: ws_live_listener.py :: state.started = True
     - Code: ws_live_listener.py :: await ws_send(state, websocket, {"type": "status", "state": "streaming"})

1. Client receives streaming ACK, transitions to listening state, starts timer
   - Evidence:
     - Code: AppState.swift :: onStatus :: if status == .streaming && self?.sessionState == .starting { self?.sessionState = .listening }
     - Code: AppState.swift :: startSession() :: startTimer()

1. Backend starts analysis loop and metrics emission for the session
   - Evidence:
     - Code: ws_live_listener.py :: state.analysis_tasks.append(asyncio.create_task(\_analysis_loop(websocket, state)))
     - Code: ws_live_listener.py :: state.metrics_task = asyncio.create_task(\_metrics_loop(websocket, state))

## Inputs and Outputs

- Inputs: audioSource (.system/.microphone/.both), user start action
- Outputs: sessionID, sessionState = .listening, WebSocket streaming status
- Side effects (writes, network calls, model loads, UI state changes): Audio capture started, WebSocket connection established, session bundle created, timer started, backend session slot acquired, ASR provider initialized

## Failure Modes

List 5â€“10 realistic failures:

- Failure: Permission denied for required audio source
  - Where detected: CGRequestScreenCaptureAccess/AVCaptureDevice.requestAccess returns false
  - Current handling (as evidenced): Set session error, abort start
  - User-visible outcome (if any): Error message "Screen Recording/Microphone permission required"
  - Evidence: AppState.swift :: setSessionError(.screenRecordingPermissionRequired)

- Failure: Audio capture start fails
  - Where detected: audioCapture.startCapture() throws
  - Current handling (as evidenced): Set session error .systemCaptureFailed, abort
  - User-visible outcome (if any): Error message with capture failure detail
  - Evidence: AppState.swift :: setSessionError(.systemCaptureFailed)

- Failure: Backend server not ready or at capacity
  - Where detected: WebSocket connection fails or backend rejects start
  - Current handling (as evidenced): Status remains .reconnecting, timeout after 5s
  - User-visible outcome (if any): Error "Backend did not start streaming within 5 seconds"
  - Evidence: AppState.swift :: startTimeoutTask

- Failure: Backend concurrency limit reached
  - Where detected: controller.acquire_session() returns False
  - Current handling (as evidenced): Backend sends error status, closes WebSocket
  - User-visible outcome (if any): Connection fails with "Server at capacity"
  - Evidence: ws_live_listener.py :: if not session_acquired

- Failure: Unsupported audio format in start message
  - Where detected: Backend validates sample_rate/format/channels
  - Current handling (as evidenced): Send error message, close WebSocket
  - User-visible outcome (if any): Connection fails with format error
  - Evidence: ws_live_listener.py :: if sample_rate != 16000 or encoding != "pcm_s16le"

## Data and Storage

- What data is produced/consumed: Session metadata (ID, attempt ID, audio source), audio format specs
- Where it is stored (DB/files/userData/etc.): In-memory session state, session bundle JSON file
- Retention / deletion controls (if documented): Session bundle persists until export/cleanup

## Observability

- Logs/events emitted: "Session starting", "WebSocket connecting", "Session started" with metadata
- Correlation IDs / session IDs (if any): session_id, attempt_id, connection_id propagated
- Metrics/traces (if any): ws_connections_total counter, active_sessions gauge
  Evidence: AppState.swift :: StructuredLogger.shared.info("Session starting"), ws_live_listener.py :: logger.info(f"Session started")

## Open Questions and Follow-up Tasks

- Questions that cannot be answered from current evidence: What happens to partial session state on failure? How are session slots released?
- Documentation gaps to fill: Detailed concurrency controller behavior
- Test gaps to add (note only, no implementation): Test session start with backend at capacity, test permission revocation mid-start</content>
  <parameter name="filePath">/Users/pranay/Projects/EchoPanel/docs/flows/EXT-004.md

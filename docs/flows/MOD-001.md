# MOD-001 Capability Detection with Tier-Based Recommendations

## Summary

- Origin: Code-only
- Status: Implemented
- 1â€“2 sentence description: Automatically detects machine capabilities (RAM, CPU, GPU) at server startup and recommends optimal ASR provider/model configuration based on hardware tier.
- Boundaries crossed: OS (hardware detection), Process (environment variable setting), Model (provider selection)
- Primary components (coarse list): CapabilityDetector, main.py lifespan, ASR provider registry

## Triggers and Preconditions

- Triggers: Server startup (FastAPI lifespan event), no explicit provider override via ECHOPANEL_ASR_PROVIDER
- Preconditions: Python dependencies available (psutil optional), server initialization

## Sequence (Happy Path)

1. **Override check**
   - Check if ECHOPANEL_ASR_PROVIDER environment variable is set
   - If set, skip auto-detection and use user-specified provider
   - Evidence:
     - Code: main.py:23-26
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:95

2. **Capability detection initialization**
   - Create CapabilityDetector instance
   - Call detect() to gather hardware profile
   - Evidence:
     - Code: main.py:29-33
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:98

3. **Hardware profile detection**
   - Detect RAM via psutil or system calls
   - Detect CPU cores via psutil or os.cpu_count()
   - Detect GPU availability (Metal MPS, CUDA)
   - Detect OS and architecture
   - Evidence:
     - Code: capability_detector.py:175-209
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:101

4. **Capability tier determination**
   - Classify machine into tier: ultra_low/low/medium/medium_gpu/high/ultra
   - Based on RAM and GPU availability
   - Evidence:
     - Code: capability_detector.py:318-349
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:107

5. **Tier-specific configuration generation**
   - Map tier to provider, model, chunk_seconds, compute_type, device, vad_enabled
   - Ultra tier gets Voxtral, high tiers get whisper.cpp with GPU, low tiers get faster_whisper CPU
   - Evidence:
     - Code: capability_detector.py:121-173
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:112

6. **Provider availability verification**
   - Check if recommended provider dependencies are installed
   - Fall back to faster_whisper if preferred provider unavailable
   - Evidence:
     - Code: capability_detector.py:354-367
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:118

7. **Environment variable configuration**
   - Set ECHOPANEL_ASR_PROVIDER, ECHOPANEL_WHISPER_MODEL, etc.
   - Configure chunk_seconds, compute_type, device, vad_enabled
   - Evidence:
     - Code: main.py:37-42
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:123

8. **Recommendation logging**
   - Log selected provider, model, and reasoning
   - Include hardware profile and any fallbacks used
   - Evidence:
     - Code: main.py:44-50
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:128

## Inputs and Outputs

- Inputs:
  - Environment variables (optional override)
  - Hardware capabilities (RAM, CPU, GPU, OS)
- Outputs:
  - Environment variables set for ASR configuration
  - MachineProfile and ProviderRecommendation objects
  - Log messages with recommendation details
- Side effects: Global environment modified, ASR provider selection locked in for session

## Failure Modes

- Failure: psutil not installed
  - Where detected: ImportError in detect()
  - Current handling: Falls back to /proc/meminfo or sysctl
  - User-visible outcome: RAM detection may be less accurate
  - Evidence: capability_detector.py:32-36

- Failure: torch not installed
  - Where detected: ImportError in GPU detection
  - Current handling: Falls back to system_profiler or nvidia-smi
  - User-visible outcome: GPU detection may be slower but still works
  - Evidence: capability_detector.py:38-42

- Failure: nvidia-smi not available
  - Where detected: subprocess timeout in \_detect_cuda()
  - Current handling: CUDA marked unavailable, CPU-only mode
  - User-visible outcome: No CUDA acceleration, falls back to CPU
  - Evidence: capability_detector.py:288-300

- Failure: Recommended provider not available
  - Where detected: is_available check returns False
  - Current handling: Falls back to faster_whisper
  - User-visible outcome: Sub-optimal but working configuration
  - Evidence: capability_detector.py:354-367

- Failure: Capability detection timeout
  - Where detected: Subprocess timeout (5s) on system calls
  - Current handling: Uses conservative defaults (8GB RAM, 4 cores, no GPU)
  - User-visible outcome: May select sub-optimal configuration
  - Evidence: capability_detector.py:263,293

- Failure: Environment variable write failure
  - Where detected: OSError when setting env vars
  - Current handling: Logs warning, continues with defaults
  - User-visible outcome: Configuration may not be applied
  - Evidence: capability_detector.py:384 (inferred)

## Data and Storage

- What data is produced/consumed: Hardware profile, capability tier, provider recommendation
- Where it is stored: In-memory objects, environment variables
- Retention / deletion controls: Environment variables persist for server lifetime

## Observability

- Logs/events emitted: Detection steps, recommendation details, fallback reasons
- Correlation IDs / session IDs: None (startup only)
- Metrics/traces: Hardware profile exposed via /capabilities endpoint
- Evidence: main.py:44-50, /capabilities endpoint

## Open Questions and Follow-up Tasks

- Questions: How to handle dynamic hardware changes during runtime?
- Documentation gaps: Tier configuration rationale, fallback priority order
- Test gaps: Hardware detection accuracy, provider availability edge cases

# MOD-009 VAD Pre-Filtering with Silero

## Summary

- Origin: Code-only
- Status: Implemented
- Voice Activity Detection pre-filtering using Silero VAD model to skip silent audio chunks, reducing ASR inference load by filtering out non-speech segments before processing.
- Boundaries crossed: Pipeline / Model
- Primary components (coarse list): VADASRWrapper, SmartVADRouter, Silero VAD model, torch.hub

## Triggers and Preconditions

- Triggers (user action, event, schedule, startup, etc.): Audio chunk received, VAD wrapper enabled
- Preconditions (permissions, settings flags, availability, model cached, etc.): VADASRWrapper or SmartVADRouter initialized, Silero VAD model available (lazy loaded)

## Sequence (Happy Path)

1. Initialize VAD wrapper with provider, threshold, and timing parameters
   - Evidence:
     - Code: server/services/vad_asr_wrapper.py:113-136
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1709-1723
2. Check VAD availability and lazy load Silero model if needed
   - Evidence:
     - Code: server/services/vad_asr_wrapper.py:151-162, 49-67
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1725-1750
3. Transcribe stream with VAD filtering, processing chunks and checking for speech
   - Evidence:
     - Code: server/services/vad_asr_wrapper.py:209-341
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1752-1810
4. Run Silero VAD on audio chunk to detect speech timestamps
   - Evidence:
     - Code: server/services/vad_asr_wrapper.py:171-207
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1812-1848
5. Skip silent chunks, pass speech chunks to provider, update stats
   - Evidence:
     - Code: server/services/vad_asr_wrapper.py:1850-1860
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1850-1860
6. Smart VAD router enables/disables VAD dynamically based on config
   - Evidence:
     - Code: server/services/vad_asr_wrapper.py:363-429
     - Docs: docs/audit/asr-model-lifecycle-20260211.md:1862-1880

## Inputs and Outputs

- Inputs: PCM audio stream, VAD threshold, min speech/silence durations
- Outputs: ASR segments (speech only), VAD statistics (frames, skip rate, time saved)
- Side effects (writes, network calls, model loads, UI state changes): Lazy model loading, stats updates

## Failure Modes

- Failure: Silero VAD download fails
  - Where detected: torch.hub.load() error
  - Current handling (as evidenced): Falls back to passthrough (all audio processed)
  - User-visible outcome (if any): Warning log, full processing
  - Evidence: vad_asr_wrapper.py:54-66
- Failure: Torch not installed
  - Where detected: ImportError
  - Current handling (as evidenced): Falls back to passthrough
  - User-visible outcome (if any): Warning log
  - Evidence: vad_asr_wrapper.py:54
- Failure: VAD model load timeout
  - Where detected: torch.hub.load() hangs
  - Current handling (as evidenced): Thread timeout, falls back to passthrough
  - User-visible outcome (if any): Warning log
  - Evidence: vad_asr_wrapper.py:54-66 (inferred)
- Failure: False speech detection (silence as speech)
  - Where detected: VAD algorithm
  - Current handling (as evidenced): Extra inference, no data loss
  - User-visible outcome (if any): Slower processing
  - Evidence: vad_asr_wrapper.py:200
- Failure: False silence detection (speech as silence)
  - Where detected: VAD algorithm
  - Current handling (as evidenced): Data loss, transcription gap
  - User-visible outcome (if any): Missing transcript
  - Evidence: vad_asr_wrapper.py:200
- Failure: Invalid sample rate
  - Where detected: Sample rate check
  - Current handling (as evidenced): Logs warning, continues (may be inaccurate)
  - User-visible outcome (if any): Warning log
  - Evidence: vad_asr_wrapper.py:139-141
- Failure: VAD threshold too high
  - Where detected: Configuration
  - Current handling (as evidenced): High false rejection rate
  - User-visible outcome (if any): Missed speech
  - Evidence: vad_asr_wrapper.py:132
- Failure: VAD threshold too low
  - Where detected: Configuration
  - Current handling (as evidenced): High false acceptance rate
  - User-visible outcome (if any): Extra processing
  - Evidence: vad_asr_wrapper.py:132

## Data and Storage

- What data is produced/consumed: Audio chunks, speech timestamps, VAD stats
- Where it is stored (DB/files/userData/etc.): In-memory stats, global model cache
- Retention / deletion controls (if documented): Session lifetime

## Observability

- Logs/events emitted: VAD load messages, skip statistics, warnings on failures
- Correlation IDs / session IDs (if any): None specific
- Metrics/traces (if any): VADStats (total_frames, speech_frames, skip_rate, infer_time_saved_ms)
- Evidence: vad_asr_wrapper.py logs, VADStats.to_dict()

## Open Questions and Follow-up Tasks

- Questions that cannot be answered from current evidence: Is VAD integrated into main ASR pipeline?
- Documentation gaps: VAD accuracy metrics, optimal thresholds
- Test gaps to add (note only, no implementation): Test VAD accuracy on different audio types, threshold tuning</content>
  <parameter name="filePath">/Users/pranay/Projects/EchoPanel/docs/flows/MOD-009.md

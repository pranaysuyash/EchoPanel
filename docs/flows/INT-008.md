# INT-008 Topic Extraction Flow

## Summary
- Origin: Doc-only
- Status: Hypothesized
- Semantic topic extraction using GLiNER model to identify meeting topics, projects, and technical terms beyond simple regex patterns, integrated into real-time analysis loop.
- Boundaries crossed: Process (GLiNER model inference) / Network (WebSocket topic updates)
- Primary components (coarse list): GLiNER service, analysis_stream.py, WebSocket

## Triggers and Preconditions
- Triggers: Real-time analysis loop cycle (every 40s during active session)
- Preconditions: GLiNER model loaded, transcript available, semantic analysis enabled

## Sequence (Happy Path)
Use numbered sequence. Each step must include evidence.
For each step:
1. <what happens>
   - Evidence:
     - Code: path :: symbol/event/string
     - Docs: path :: heading/snippet
   - Notes: (only if needed)

1. Analysis loop triggers topic extraction phase
   - Evidence:
     - Code: Hypothesized - not implemented
     - Docs: docs/NER_PIPELINE_ARCHITECTURE.md :: Semantic Layer (GLiNER)

2. Snapshot current transcript segments
   - Evidence:
     - Code: Hypothesized - similar to existing extract_entities
     - Docs: docs/flow-atlas-20260211.md :: INT-008 Topic Extraction Flow

3. Run GLiNER inference on transcript text with topic labels
   - Evidence:
     - Code: Hypothesized - GLiNER service not implemented
     - Docs: docs/NER_PIPELINE_ARCHITECTURE.md :: GLiNER is treated as a modular model service

4. Extract topics with confidence scores and evidence pointers
   - Evidence:
     - Code: Hypothesized - not implemented
     - Docs: docs/NER_PIPELINE_ARCHITECTURE.md :: Every extraction must emit a standard Evidence Pointer

5. Merge with existing regex-based topics using deduplication
   - Evidence:
     - Code: Hypothesized - not implemented
     - Docs: docs/NER_PIPELINE_ARCHITECTURE.md :: The Hybrid Model - separate deterministic from probabilistic

6. Send topics_update WebSocket message to client
   - Evidence:
     - Code: Hypothesized - not implemented
     - Docs: Assumed from pattern of other analysis updates

## Inputs and Outputs
- Inputs: Transcript segments with text and timestamps
- Outputs: WebSocket topics_update message with semantic topics, confidence scores, evidence pointers
- Side effects (writes, network calls, model loads, UI state changes): GLiNER model loaded on demand, WebSocket message sent

## Failure Modes
List 5â€“10 realistic failures:
- Failure: GLiNER model not available/download failed
  - Where detected: Model loading phase
  - Current handling: Hypothesized - fallback to regex topics
  - User-visible outcome: Basic topic extraction continues
  - Evidence: Hypothesized based on model lifecycle patterns

- Failure: GLiNER inference timeout
  - Where detected: Inference call
  - Current handling: Hypothesized - timeout and skip cycle
  - User-visible outcome: Topics not updated for this cycle
  - Evidence: Hypothesized based on existing analysis timeouts

- Failure: Low confidence topics filtered out
  - Where detected: Post-processing
  - Current handling: Hypothesized - confidence threshold applied
  - User-visible outcome: Fewer topics extracted
  - Evidence: Hypothesized from ML best practices

- Failure: Memory OOM during GLiNER inference
  - Where detected: Model runtime
  - Current handling: Hypothesized - degrade to CPU or skip
  - User-visible outcome: Analysis delayed or skipped
  - Evidence: Hypothesized based on model failure modes

- Failure: WebSocket send failure
  - Where detected: ws_send function
  - Current handling: Hypothesized - exception handling
  - User-visible outcome: Client doesn't receive topic updates
  - Evidence: Hypothesized from existing patterns

## Data and Storage
- What data is produced/consumed: Transcript text, extracted topics with metadata
- Where it is stored (DB/files/userData/etc.): In-memory for real-time, persisted in session bundle
- Retention / deletion controls (if documented): Topics retained with session data

## Observability
- Logs/events emitted: Inference timing, confidence scores, WebSocket topics_update events
- Correlation IDs / session IDs (if any): Session ID in updates
- Metrics/traces (if any): Model inference latency, topic count metrics
Evidence: Hypothesized based on existing observability patterns

## Open Questions and Follow-up Tasks
- Questions that cannot be answered from current evidence: GLiNER model size and performance requirements? Integration points with existing analysis loop?
- Documentation gaps to fill: Detailed GLiNER configuration, model selection criteria
- Test gaps to add (note only, no implementation): GLiNER inference accuracy testing, performance benchmarking, fallback behavior testing
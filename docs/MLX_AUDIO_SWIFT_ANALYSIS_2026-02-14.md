# MLX Audio Swift - Comprehensive Analysis for EchoPanel

**Date:** 2026-02-14  
**Analyst:** Agent Research  
**Status:** ðŸ”´ CRITICAL FINDING - Could eliminate Python backend entirely

---

## Executive Summary

**MLX Audio Swift** is a native Swift SDK for audio processing on Apple Silicon that could **completely replace EchoPanel's Python backend** for ASR. It provides:

- Native macOS/iOS speech-to-text with Metal GPU acceleration
- No Python server required
- Real-time streaming transcription
- Speaker diarization
- Lower latency than server-based approaches

**Verdict:** This is a game-changer for EchoPanel architecture.

---

## What is MLX Audio Swift?

**Repository:** https://github.com/Blaizzy/mlx-audio-swift  
**Parent Project:** https://github.com/Blaizzy/mlx-audio (Python)

### Architecture

MLX Audio Swift follows a **modular design**:

```
MLXAudioCore        - Base types, protocols, utilities
MLXAudioCodecs      - Audio codec implementations (SNAC, Vocos, Mimi)
MLXAudioTTS         - Text-to-Speech models
MLXAudioSTT         - Speech-to-Text models (ASR)
MLXAudioVAD         - Voice Activity Detection & Speaker Diarization
MLXAudioSTS         - Speech-to-Speech (future)
MLXAudioUI          - SwiftUI components
```

### Installation

```swift
// Package.swift
dependencies: [
    .package(url: "https://github.com/Blaizzy/mlx-audio-swift.git", branch: "main")
]

// Import only what you need
.product(name: "MLXAudioSTT", package: "mlx-audio-swift"),
.product(name: "MLXAudioVAD", package: "mlx-audio-swift")
```

---

## Supported ASR Models (STT)

| Model | Params | Languages | Features | Repo |
|-------|--------|-----------|----------|------|
| **Whisper** | Various | 99+ | Robust, proven | mlx-community/whisper-* |
| **Qwen3-ASR** | 0.6B/1.7B | 52+ langs | Streaming, SOTA | mlx-community/Qwen3-ASR-* |
| **Parakeet** | 0.6B | 25 EU langs | NVIDIA quality | mlx-community/parakeet-* |
| **Voxtral Realtime** | 4B | Multiple | Streaming, low latency | mlx-community/Voxtral-* |
| **VibeVoice-ASR** | 9B | Multiple | Diarization + timestamps | mlx-community/VibeVoice-* |
| **GLMASR** | Nano | Multiple | Swift-native | mlx-community/GLM-ASR-* |

### For EchoPanel: Recommended Models

1. **Primary:** Qwen3-ASR-0.6B-8bit
   - Fastest RTF (~0.064 claimed)
   - Native streaming
   - 52 languages
   - Quantized for efficiency

2. **Alternative:** Whisper (mlx-community/whisper-large-v3-turbo-asr-fp16)
   - Battle-tested
   - 99 languages
   - Proven reliability

3. **Premium:** VibeVoice-ASR (9B)
   - Built-in speaker diarization
   - Word-level timestamps
   - Meeting transcription optimized

---

## Swift Code Examples

### Basic STT Usage

```swift
import MLXAudioSTT
import MLXAudioCore

// Load audio file
let (sampleRate, audioData) = try loadAudioArray(from: audioURL)

// Load STT model
let model = try await GLMASRModel.fromPretrained("mlx-community/GLM-ASR-Nano-2512-4bit")

// Transcribe
let output = model.generate(audio: audioData)
print(output.text)
```

### Streaming Transcription (Real-time)

```swift
import MLXAudioSTT

let model = try await Qwen3ASRModel.fromPretrained("mlx-community/Qwen3-ASR-0.6B-8bit")

// Stream tokens as they're generated
for try await event in model.generateStream(audio: audioStream) {
    switch event {
    case .token(let token):
        print("Token: \(token)", terminator: "")
    case .audio(let audio):
        print("\nAudio segment generated")
    case .info(let info):
        print(info.summary)
    }
}
```

### Speaker Diarization (Who spoke when)

```swift
import MLXAudioVAD
import MLXAudioCore

// Load audio
let (sampleRate, audioData) = try loadAudioArray(from: audioURL)

// Load diarization model
let model = try await SortformerModel.fromPretrained(
    "mlx-community/diar_streaming_sortformer_4spk-v2.1-fp16"
)

// Detect speakers
let output = try await model.generate(audio: audioData, threshold: 0.5)
for segment in output.segments {
    print("Speaker \(segment.speaker): \(segment.start)s - \(segment.end)s")
}
```

### With Custom Parameters

```swift
let parameters = GenerateParameters(
    maxTokens: 1200,
    temperature: 0.7,
    topP: 0.95,
    repetitionPenalty: 1.5,
    repetitionContextSize: 30
)

let audio = try await model.generate(text: "Your text here", parameters: parameters)
```

---

## How MLX Audio Swift Fits EchoPanel

### Current Architecture (With Python Backend)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebSocket      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   macOS App     â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Python Server   â”‚
â”‚  (Swift/SwiftUI)â”‚                     â”‚  (FastAPI + ASR) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚  MLX Whisper â”‚
                                        â”‚  faster-whispâ”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Issues:**
- Python server complexity
- WebSocket latency
- Process management
- Deployment complexity

### Proposed Architecture (MLX Audio Swift)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    macOS App (Swift)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              MLX Audio Swift                     â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚ Qwen3-ASR    â”‚  â”‚ Sortformer (Diarization)â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ (STT/ASR)    â”‚  â”‚ (Who spoke when)        â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Audio Capture (ScreenCaptureKit)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Metal GPU  â”‚
                    â”‚  (M1/M2/M3)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Advantages:**
- âœ… No Python server needed
- âœ… Zero WebSocket latency
- âœ… Native Metal GPU acceleration
- âœ… Simpler deployment (single .app)
- âœ… Better battery life (unified memory)
- âœ… Real-time streaming

---

## Performance Comparison

| Metric | Python Backend | MLX Audio Swift |
|--------|---------------|-----------------|
| **Latency** | 50-100ms (network) | 0ms (local) |
| **RTF (whisper.cpp)** | 0.028x (35Ã— real-time) | Similar or better |
| **Memory** | Python + model + overhead | Just model (unified) |
| **CPU Usage** | High (Python overhead) | Low (native) |
| **Battery** | Higher drain | Optimized for Apple Silicon |
| **Offline Capability** | Requires local server | Native |
| **Deployment** | Complex (Python + models) | Simple (bundled) |

---

## Requirements for EchoPanel

### System Requirements
- **macOS 14+** (Sonoma or later)
- **Apple Silicon** (M1/M2/M3/M4)
- **Xcode 15+**
- **Swift 5.9+**

### Model Storage

| Model | Size | Quantization |
|-------|------|--------------|
| Qwen3-ASR-0.6B-8bit | ~300MB | 8-bit |
| Whisper-turbo | ~1GB | FP16 |
| Sortformer (diarization) | ~500MB | FP16 |
| **Total** | **~1.8GB** | Bundled in .app |

---

## Implementation Plan for EchoPanel

### Phase 1: Proof of Concept (1-2 days)

```swift
// Test MLX Audio Swift integration
import MLXAudioSTT

class NativeASRManager: ObservableObject {
    private var model: Qwen3ASRModel?
    
    func initialize() async throws {
        model = try await Qwen3ASRModel.fromPretrained(
            "mlx-community/Qwen3-ASR-0.6B-8bit"
        )
    }
    
    func transcribe(audioData: [Float]) async throws -> String {
        guard let model = model else {
            throw ASRError.notInitialized
        }
        let output = model.generate(audio: MLXArray(audioData))
        return output.text
    }
}
```

### Phase 2: Streaming Integration (3-5 days)

Replace WebSocket-based transcription with native streaming:

```swift
class StreamingTranscriptionManager {
    private var audioCapture: AudioCaptureManager
    private var asrModel: Qwen3ASRModel
    
    func startStreaming() async throws {
        // Direct connection between audio capture and ASR
        for await audioChunk in audioCapture.audioStream {
            for try await event in asrModel.generateStream(audio: audioChunk) {
                handleTranscriptionEvent(event)
            }
        }
    }
}
```

### Phase 3: Speaker Diarization (2-3 days)

Add native speaker identification:

```swift
class DiarizationManager {
    private var diarizationModel: SortformerModel
    
    func identifySpeakers(in audio: MLXArray) async throws -> [SpeakerSegment] {
        let output = try await diarizationModel.generate(audio: audio)
        return output.segments.map { segment in
            SpeakerSegment(
                speakerId: segment.speaker,
                startTime: segment.start,
                endTime: segment.end
            )
        }
    }
}
```

### Phase 4: Remove Python Backend (5-7 days)

1. Remove FastAPI server
2. Remove WebSocket connection
3. Bundle MLX Audio Swift models
4. Simplify deployment to single .app

---

## Pros and Cons

### âœ… Advantages

1. **Native Performance**
   - Metal GPU acceleration
   - No Python overhead
   - Unified memory (no copies)

2. **Simplified Architecture**
   - Single codebase (Swift)
   - No server management
   - Easier debugging

3. **Better User Experience**
   - Lower latency
   - Offline capable
   - Better battery life

4. **Modern API**
   - Swift async/await
   - Type-safe
   - Native error handling

### âŒ Disadvantages

1. **macOS 14+ Required**
   - Drops support for older macOS versions
   - May affect user base

2. **Apple Silicon Only**
   - Intel Macs not supported
   - Could exclude some users

3. **Model Availability**
   - Limited to mlx-community models
   - Custom models need conversion

4. **Development Maturity**
   - Relatively new project
   - Potential API changes

---

## Risk Assessment

| Risk | Severity | Mitigation |
|------|----------|------------|
| MLX Audio Swift API changes | Medium | Pin to stable version |
| Model quality vs Python | Low | Test with same audio |
| Memory pressure with large models | Medium | Use quantized models |
| Missing features vs Python | Medium | Fallback to Python mode |

---

## Recommendation

### Immediate Action (Recommended)

**Create a proof-of-concept branch testing MLX Audio Swift:**

```bash
# 1. Create feature branch
git checkout -b feature/mlx-audio-swift-poc

# 2. Add MLX Audio Swift dependency
# Edit Package.swift or use Xcode SPM

# 3. Implement basic STT
# Create NativeASRManager.swift

# 4. Compare with Python backend
# Run same audio through both
```

### Long-term Strategy

**Hybrid Approach (Recommended):**

```swift
enum ASRProvider {
    case nativeMLX      // New: MLX Audio Swift
    case pythonServer   // Current: Python backend
}

class TranscriptionManager {
    var provider: ASRProvider = .nativeMLX
    
    func transcribe(audio: Data) async throws -> String {
        switch provider {
        case .nativeMLX:
            return try await nativeASR.transcribe(audio)
        case .pythonServer:
            return try await pythonASR.transcribe(audio)
        }
    }
}
```

This allows:
- Gradual migration
- Fallback if issues arise
- A/B testing

---

## Code Sample: Complete Integration

```swift
import MLXAudioSTT
import MLXAudioVAD
import Combine

@MainActor
class EchoPanelASRManager: ObservableObject {
    // Published state for UI
    @Published var transcription: String = ""
    @Published var isTranscribing: Bool = false
    @Published var speakerSegments: [SpeakerSegment] = []
    
    // Models
    private var asrModel: Qwen3ASRModel?
    private var diarizationModel: SortformerModel?
    
    // Audio capture
    private let audioCapture = AudioCaptureManager()
    private var cancellables = Set<AnyCancellable>()
    
    // MARK: - Initialization
    
    func initialize() async throws {
        // Load models
        asrModel = try await Qwen3ASRModel.fromPretrained(
            "mlx-community/Qwen3-ASR-0.6B-8bit"
        )
        
        diarizationModel = try await SortformerModel.fromPretrained(
            "mlx-community/diar_streaming_sortformer_4spk-v2.1-fp16"
        )
        
        // Setup audio capture
        audioCapture.onPCMFrame = { [weak self] pcmData, source in
            Task {
                await self?.processAudioChunk(pcmData)
            }
        }
    }
    
    // MARK: - Streaming Transcription
    
    private func processAudioChunk(_ data: Data) async {
        guard let model = asrModel else { return }
        
        do {
            // Convert Data to MLXArray
            let audioArray = MLXArray(data.toFloatArray())
            
            // Stream transcription
            for try await event in model.generateStream(audio: audioArray) {
                switch event {
                case .token(let token):
                    await MainActor.run {
                        self.transcription += token
                    }
                case .info(let info):
                    print("Generation info: \(info)")
                default:
                    break
                }
            }
        } catch {
            print("Transcription error: \(error)")
        }
    }
    
    // MARK: - Speaker Diarization
    
    func performDiarization(audioURL: URL) async throws {
        guard let model = diarizationModel else {
            throw ASRError.modelNotLoaded
        }
        
        let (sampleRate, audioData) = try loadAudioArray(from: audioURL)
        let output = try await model.generate(audio: audioData, threshold: 0.5)
        
        await MainActor.run {
            self.speakerSegments = output.segments.map { seg in
                SpeakerSegment(
                    speakerId: seg.speaker,
                    startTime: seg.start,
                    endTime: seg.end
                )
            }
        }
    }
}

// MARK: - Supporting Types

struct SpeakerSegment: Identifiable {
    let id = UUID()
    let speakerId: Int
    let startTime: Float
    let endTime: Float
}

enum ASRError: Error {
    case modelNotLoaded
    case notInitialized
    case audioConversionFailed
}

// MARK: - Data Extensions

extension Data {
    func toFloatArray() -> [Float] {
        let count = self.count / MemoryLayout<Int16>.size
        return self.withUnsafeBytes { buffer in
            let int16Buffer = buffer.bindMemory(to: Int16.self)
            return (0..<count).map { Float(int16Buffer[$0]) / 32768.0 }
        }
    }
}
```

---

## Conclusion

**MLX Audio Swift is a paradigm shift for EchoPanel.**

It offers:
- âœ… Native macOS performance
- âœ… Simplified architecture
- âœ… Real-time streaming
- âœ… Speaker diarization
- âœ… Offline capability

**Recommendation:** 
1. Immediately create a proof-of-concept
2. Compare quality/performance with Python backend
3. Plan gradual migration
4. Consider making it the default for macOS 14+ users

**Impact:** This could reduce EchoPanel's complexity by 50% while improving performance.

---

## Resources

- **MLX Audio Swift:** https://github.com/Blaizzy/mlx-audio-swift
- **MLX Audio (Python):** https://github.com/Blaizzy/mlx-audio
- **MLX Framework:** https://github.com/ml-explore/mlx
- **MLX Swift:** https://github.com/ml-explore/mlx-swift
- **WWDC 2025 MLX:** https://developer.apple.com/videos/play/wwdc2025/315/
